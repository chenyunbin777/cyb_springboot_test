# 07.行锁功过：怎么减少行锁对性能的影响？

# 两阶段锁
- 在InnoDB I 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

# 死锁和死锁检测
- 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致 这几个线程都进入无限等待的状态，称为死锁。
- 解决思索的策略
  - 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置
    - 默认值是50s
    - 1 如果设置太长，需要等待很长时间才会解锁，一般来说对于线上的程序是不可以接受的
    - 2 如果设置太短的话，比如1s，如果不是死锁只是简单的锁等待呢？会出现误伤的情况
  - 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事 务得以继续执行。将参数**innodb_deadlock_detect设置为on**，表示开启这个逻辑。
    - 一般会采用这种策略，
    - 弊端：**热点行更新导致的性能问题**
      - 问题描述：
      - 你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。
      - 那如果是我们上面说到的所有事务都要更新同一行的场景呢？每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n)的操作。
      - 假设有**1000个并发线**程要同时更新同一行，那么死锁检测操作就是100万这个量级 的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。
      因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。
      - 解决办法
        - 1、一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
        - 2、另一个思路是控制并发度
          - 比如同一行同时 最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。
          - 修改Mysql源码，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。


# 问题
- 如果你要删除一个表里面的前10000行数据，有以下三种方法可 以做到： 
  - 第一种，直接执行delete fromTlimit 10000; 
  - 第二种，在一个连接中循环执行20次 delete fromTlimit 500; 
  - 第三种，在20个连接中同时执行delete fromTlimit 500。 你会选择哪一种方法呢？为什么呢？
- 答：第二种：
  - 第一种方式（即：直接执行delete fromTlimit 10000）里面，单个语句占用时间长，锁的时间也 比较长；而且大事务还会导致主从延迟。
  - 第三种方式（即：在20个连接中同时执行delete from limit 500），会人为造成锁冲突。