# SOFATracer 
- 是一个用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，服务治理等。
- https://github.com/sofastack/sofa-tracer?spm=a2c6h.12873639.article-detail.7.109a16cac1Q5Zm



# 如何动态串联业务日志？怎么样实现链路traceId的透传，实现最小化的代码侵入？
## 1 链路染色
- “链路染色”的含义为：在链路执行过程中，通过**透传****串联标识**，明确具体是哪条链路在执行，执行到了哪个节点
- 步骤一：
    - 确定串联标识，当逻辑链路开始时，确定唯一的标识，能够明确后续哪一条链路在执行，执行到了哪个节点。
    - 链路唯一标识 = **业务标识 + 场景标识 + 执行标识** （三个标识共同决定“某个业务场景下的某次执行”）
        - 业务标识：赋予链路业务含义：是哪个人 或者 哪个一个活动，使用user id或者活动id。
        - 场景标识：赋予链路场景含义：如 文件预览，文件编辑，文件收藏等等，可以定义个唯一的标识。
        - 执行标识：赋予链路执行含义：执行调用了哪个方法，或者哪些RPC调用
    - 节点唯一标识  =  链路唯一标识 + 节点名称 （两个标识共同决定“某个业务场景下的某次执行中的某个逻辑节点”），例如 在v2（节点名称）中 张三（业务标识） 预览（场景）了一个文件，调用了info接口（执行标识）
        - 节点名称：DSL中预设的节点唯一名称，如“A”。
        
        
- 业务逻辑执行时的日志数据原本是离散存储的，而此时需要实现的是，随着业务逻辑的执行动态串联各个逻辑节点的日志，进而还原出完整的业务逻辑执行现场。
  由于逻辑节点之间、逻辑节点内部往往通过MQ或者RPC等进行交互，新方案可以采用分布式会话跟踪提供的**分布式参数透传能力**[5]实现业务日志的动态串联：
  通过在执行线程和网络通信中持续地透传参数，实现在业务逻辑执行的同时，不中断地传递链路和节点的标识，实现离散日志的**染色**。
  
  基于标识，染色的离散日志会被动态串联至正在执行的节点，逐渐汇聚出完整的逻辑链路，最终实现业务执行现场的高效组织和可视化展示。
  与分布式会话跟踪方案不同的是，**当同时串联多次分布式调用时，新方案需要结合业务逻辑选取一个公共id作为标识**，例如图5的审核场景涉及2次RPC调用，
  为了保证2次执行被串联至同一条逻辑链路，此时结合审核业务场景，选择初审和复审相同的“任务id”作为标识，完整地实现审核场景的逻辑链路串联和执行现场还原。
  
## 2 链路上报
- “链路上报”的含义为：在链路执行过程中，将日志以链路的组织形式进行上报，实现业务现场的准确保存。 

## 3 链路存储
- “链路存储”的含义为：将链路执行中上报的日志落地存储，并用于后续的“现场还原”。上报日志可以拆分为链路日志、节点日志和业务日志三类：
    - 链路日志：链路单次执行中，从开始节点和结束节点的日志中提取的链路基本信息，包含链路类型、链路元信息（配置信息）、链路开始/结束时间等。 
        - 一条链路：就相当于 一个功能执行的开始到结束，如 预览：从点击文件开始到文件展示出来算是一条链路
    - 节点日志：链路单次执行中，已执行节点的基本信息，包含节点名称、节点状态、节点开始/结束时间等。
    （节点指的应该是不同的服务 v2，galaxy，wps等）
    - 业务日志：链路单次执行中，已执行节点中的业务日志信息，包含日志级别、日志时间、日志数据等。 
    （各个不同的业务接口或者方法中的信息）
    - 我们可以使用AOP的方式来处理一个链路，一个节点 的执行开始与结束信息
    
    

# 基础架构
- log_agent：日志代理服务，通过封装slfj4框架进行**异步的**日志的接收与处理，并统一传输至kafka通道中。
- 中转应用：对于部分不兼容kafka的服务 通过 "中转应用" 来传输数据到kafka
- kafka：用于异步日志的接收，特点就是实现亿量级的数据处理，将数据接入到Flink
- Flink：根据日志的类型进行分类与聚合，解析为链路日志，节点日志，业务日志。（支持海量数据的实时处理）
- HBase：完成日志解析之后，会按照树形结构进行落地存储，