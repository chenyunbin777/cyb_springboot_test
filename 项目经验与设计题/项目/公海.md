# 背景
- 1 现有弹个车业务，线索的筛选与利用是一次性的。
    - 已关闭的门店中存在着大量的客户资源，没有被重新分配和利用，2019年上半年数量超过180万。
    - 还有的就是已销售会对客户进行分级，一些优先等级比较低的客户的跟进行为不是特别的好，效率不是很高，我们需要将此类的线索进行重新分配给其他的一些销售重新跟进，有可能会有很好的效果。
    会有高的承担的概率，因为每个销售水品都是不一样的。
    - 还有销售主动设置为 没有意向的客户（战败或者无效的），我们也应该重新的利用，有可能这些客户的购车意向会有一个更新。我们应该时刻的进行关注。

- 2 单一销售对于客户的跟进缺乏持续性


#  如何做
## 难点：这些没有被重新利用的数据，我们如何筛选，如何保存，并且开放给所有的销售来使用呢？
- 我们的实现办法：我们以城市为单位，将未能有效转化的客户回流到我们的一个**客户公海当中**
    - 客户公海的实现：我们每天晚上会跑对应的任务，将我们的Mysql表中给的数据迁移到我们的hive表中进行整合数据，这是一个T+1的操作。
    然后我们将整合好的数据在迁移到我们的Mysql对应的公海数据表当中。
    - 销售的领取的实现：我们是一个分布式的服务，公海的一个服务是分布在4台服务器中。我们如何保证领取的一个安全性呢？保证不会有当天的相同的客户被领取到多个销售身上呢？
        - 这时就要考虑到分布式锁的概念，来保证数据的安全性和业务的正确性。
        - 我们用的是Redis的分布式锁，过期时间是3s，我们以城市为锁，进行锁定，保证业务安全性。
        - 我们分布式锁遇到的问题：总会有个别的客户别领取到了不同的销售身上。
            - 原因：经我们的分析与验证，发现是有个别的领取过程时间过长，导致还没有领取完成时，又有一个新的请求过来领取客户，导致了领取到了与上次请求相同的客户。
            - 我们的解决办法：就是根据线上的日志观察，一般的执行时间最多也不会超过5s，所以我们调整了，redis锁的过期时间到5s。 这时就没有了这种现象。
            
    
           
    