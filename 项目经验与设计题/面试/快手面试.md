# mysql：
可重复读隔离级别下：增删改查：其中哪些会用到什么锁？
1 查询（select）：读取不会占用和等待表上的锁，除非加select 。。。 for update（强制性加锁，间隙锁 （】）
2 更新（update set...）:
UPDATE accounts SET level = 100 WHERE id = 5;   如果是唯一索引，那么会加对应的“行锁”
UPDATE accounts SET level = 100 WHERE a = 5;   如果是辅助索引，那么记录锁不仅会加在这个二级索引上，还会加在这个二级索引所对应的聚簇索引上。 如 a = 5 的id有 1 2 3 4 这些记录都会加行锁。
3 插入（insert into）
delect insert update加的锁要看匹配的列是不是有索引决定是不是锁表，不一定是行锁

1 MVCC：多版本并发控制
下面两个采用的都是非锁定的一致性读操作，不会等待delete 或者 update锁释放，会读取一个快照数据。下面对于快照数据的定义也是不同的
Read Commited： 总是读取行的最新版本（提交之后的最新数据），所以违反了事务ACID中的，隔离性（事务之间的处理都是隔离的）
Repeatable read：总是读取事务开始时的行数据

Serialziable：快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读
- 之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，
但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本
- 说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现 


2 对于非锁定的一致性读操作，就算是加了独占锁select 。。。 for update，也是可以进行读取的。

3 间隙锁(左开，右开)，next-key-lock（锁定范围包括记录本身，左开右毕）必须在Repeatable Read级别下才生效：  id： 1  2  5  6   a: 1 1 3 6
3.1 唯一索引。主键索引：where id = 5，会锁定。id = 5 的 这条记录
3.2 副主索引：select * from table where b=3 for update 会根据next-key-lock锁定范围 (1,3]，特别注意的是，innodb引擎还会对辅助索引的下一个减值加上 gap lock，即辅助索引的范围(3,6)也会被锁定

4 LOCK_AUTO_INC：自增锁，一种特殊的表锁，自增值必须是索引，同事必须是索引的第一个列。 insert into 时会加表锁


最左前缀：mysql 会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配。范围列可以用到索引，但是范围列后面的列无法用到索引。

覆盖索引：
- 就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。
- 
d 建立了一个索引
explain select d from cyb_test where d like '%1'  可以使用到d索引



a = X and b>xx and c= XX
select a from table  where a like %XXX;


# volatile 应用场景

# 线程池：shutdown 原理: 
private void interruptIdleWorkers(boolean onlyOne) {
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
        循环遍历所有的worker线程任务
            for (Worker w : workers) {
                Thread t = w.thread;
                如果worker线程没有中断，并且可以获取到线程执行的lock锁时，说明当前线程是空闲状态 可以被中断
                if (!t.isInterrupted() && w.tryLock()) {
                    try {
                        t.interrupt();
                    } catch (SecurityException ignore) {
                    } finally {
                        w.unlock();
                    }
                }
                if (onlyOne)
                    break;
            }
        } finally {
            mainLock.unlock();
        }
    }



# 并发容器
java.util.concurrent包中提供了多种并发类容器。
1.ConcurrentHashMap

对应的非并发容器：HashMap

目标：代替Hashtable、synchronizedMap，支持复合操作

原理：JDK6中采用一种更加细粒度的加锁机制Segment“分段锁”，JDK8中采用CAS无锁算法。

2.CopyOnWriteArrayList
原理：并发版 ArrayList，底层结构也是数组，和 ArrayList 不同之处在于：当新增和删除元素时会创建一个新的数组，在新的数组中增加或者排除指定对象，
最后用新增数组替换原来的数组。
    - ReentrantLock lock = this.lock 添加删除操作 加锁保证了并发的安全
    - 但是读取不会加锁，有可能读取到脏数据，适用于读多写少的情况

对应的非并发容器：ArrayList
目标：代替Vector、synchronizedList
适用场景：由于读操作不加锁，写（增、删、改）操作加锁，因此适用于读多写少的场景。
局限：由于读的时候不会加锁（读的效率高，就和普通 ArrayList 一样），读取的当前副本，因此可能读取到脏数据。如果介意，建议不用。  
   
3.CopyOnWriteArraySet
对应的非并发容器：HashSet
目标：代替synchronizedSet
原理：基于CopyOnWriteArrayList实现，其唯一的不同是在add时调用的是CopyOnWriteArrayList的addIfAbsent方法，其遍历当前Object数组，如Object数组中已有了当前元素，则直接返回，如果没有则放入Object数组的尾部，并返回。

4.ConcurrentSkipListMap
对应的非并发容器：TreeMap
目标：代替synchronizedSortedMap(TreeMap)
原理：SkipList 即跳表，跳表是一种空间换时间的数据结构，通过冗余数据，将链表一层一层索引，达到类似二分查找的效果
    - **是基于一种乐观锁的方式去实现高并发。**
应用：多线程程序中，如果需要对Map的键值进行排序时，请尽量使用ConcurrentSkipListMap，可能得到更好的并发度
    - 会对key值进行排序
数据结构：下面说说Java中ConcurrentSkipListMap的数据结构。
(01) ConcurrentSkipListMap继承于AbstractMap类，也就意味着它是一个哈希表。
(02) Index是ConcurrentSkipListMap的内部类，它与“跳表中的索引相对应”。HeadIndex继承于Index，ConcurrentSkipListMap中含有一个HeadIndex的对象head，head是“跳表的表头”。
(03) static class Index是跳表中的索引，它包含“右索引的指针(right)”，“下索引的指针(down)”和“哈希表节点node”。node是Node的对象，Node也是ConcurrentSkipListMap中的内部类。

5.ConcurrentSkipListSet
对应的非并发容器：TreeSet
目标：代替synchronizedSortedSet
原理：内部基于ConcurrentSkipListMap实现
- 类似 HashSet 和 HashMap 的关系，ConcurrentSkipListSet 里面就是一个 ConcurrentSkipListMap，就不细说了。

6.ConcurrentLinkedQueue
不会阻塞的队列
对应的非并发容器：Queue
原理：基于链表实现的FIFO队列（LinkedList的并发版本）
基于链表实现的并发队列，使用乐观锁 (CAS) 保证线程安全。因为数据结构是链表，所以理论上是没有队列大小限制的，也就是说添加数据一定能成功。

7.LinkedBlockingQueue、ArrayBlockingQueue、PriorityBlockingQueue、Syn
对应的非并发容器：BlockingQueue
特点：拓展了Queue，增加了可阻塞的插入和获取等操作
原理：通过ReentrantLock实现线程安全，通过Condition实现阻塞和唤醒




# 垃圾回收器的使用场景
##  CMS

## G1
https://blog.csdn.net/u011069294/article/details/108280100

- **Remembered Set保证了 避免GC时的全堆扫描：** 
    - 1 每个region中都会有一个与之对应的Remembered Set
    - 2被引用对象的引用相关系会记录到它对应的Remembered Set中，这就保证了在可达性分析的时候 GC Root向下搜索引用的时候，直接查找Remembered Set就好
不用全对堆的去查找（比如 老年代对象OldObject引用了年轻代对象YObject ，直接查找Remembered Set中的引用关系就好）

- 阶段
    - 1 初始标记：与CMS相同，标记GC Root的可以直接关联到的对象，STW停段时间很短。
    - 2 并发标记

- 优势
    - 1 并行与并发：多GC线程同时工作（并行），GC与用户线程交替执行（并发）
    - 2 分代收集：将堆划分为多个Region，不要求整个Eden区，年轻代，或者老年代都是连续的。兼顾年轻代和老年代的回收任务。
    - 3 内存碎片整理：
        - 1 region为回收单位，Region之间使用 **"复制算法"**
        - 2 整体上看是**标记-整理算法**，两种算法都能避免内存碎片。
        - 3 这种特性避免了**分配大对象**时不会因为找不到连续的空间而出发GC。 **尤其是Java堆越大，G1优势更大**
        - 4 可预测的停顿模型
            - 1 维护Region回收的优先级列表（回收所得空间大小和回收所需时间的经验值）
            - 2 长度为M的时间段，设置停顿时间不超过N ms
        - G1停顿在最差的情况要比CMS好很多。
        
- 缺点
    - 1 相比于CMS，还不具有压倒性优势。 
        - 比如GC收集产生的 **内存占用**，以及程序运行时的**额外执行负载（OverLoad）**都比CMS高
    - 2 经验上来说：小内存CMS大概率优于G1.  **平衡点在 6~8G之间。**
    - 3 想要大吞吐量G1不是个好的选择
- 配置参数
-XX:G1HeapRegionSize 设置每个region的大小，值只能是2的n次方（1,2，4,8，16,32），范围是1MB到32MB。
-XX:MaxGCPauseMillis 设置期望达到（JVM会尽力实现，**但不保证**）的最大GC停顿时间，默认是200ms。 
这个参数如果设置的过小，会导致一次回收的region个数减少，回收的垃圾对象减少(因为设置的垃圾线程工作的时间减少了)，如果产生垃圾的速度很快，可能会导致Full GC。
-XX:ParallelGCThread 设置STW的时候并行的垃圾线程数量。
-XX:ConcGCThreads 设置用户线程与垃圾收集线程并发的时候，垃圾收集线程的线程数量

- **通常使用G1收集器，不需要那么多的参数配置**。只需要进行下图所示的3步。其他的参数，G1会自动调节或使用默认的参数。
    - 1 开启G1垃圾回收器（JDK1.9默认：取代了CMS以及Parallel + Parallel Old组合，在JDK7以及JDK8中，可以使用-XX:+UseG1GC来启用。）
    - 2 设置堆的最大内存
        -Xms4g  堆初始大小 4g
        -Xmx4g  最大堆大小 4g
    - 3 设置最大的停顿时间：-XX:MaxGCPauseMillis
- G1提供了三种垃圾回收模式：YoungGC，Mixed GC和 Full GC，在不同的条件下触发、。

- 应用场景：
    - 1 面向服务端应用有大内存，多处理器的机器（在普通大小堆里表现并不惊喜）
    - 2 主要的应用是需要低GC停顿延时，并具有大堆的应用程序提供解决方案
        - 如:在堆大小为约为6G或者更大时，可预测停顿时间可以低于0.5s
        - G1通过每次只清理一部分的而不是全部的Region（根据优先级排序过了）的增量式清理来保证每次GC停顿时间不会过长
    - 3 用来替代JDK1.5中CMS收集器，可能比CMS要好
        - 1 超过50%的Java堆被活动数据占用
        - 2 对象分配频率或者年代提升频率变化快（常见对象多 并且 年轻代晋升到老年代的对象更多）
        - 3 GC停顿时间过长（长于0.5~1s）
         
    - 4 HotSpot垃圾收集器 除了G1以外，其他的垃圾收集器使用JVM内置的线程执行GC的多线程操作。
    而G1可以使用应用线程来帮助GC回收过程。 


## 分享码的高并发处理，分布式缓存 容错 缓存 异步MQ 削峰 

## 分库分表
## 迁移数据
同步双写
## 热点数据处理
根据时间来判断是否是热点数据
比如用户数据。数据库有2000w条。
活跃用户：
redis sortSet里 放两天内(为方便取一天内活跃用户)登录过的用户，登录一次ZADD一次，如set已存在则覆盖其分数（登录时间）。
键：login:users，值：分数 时间戳、value userid。设置一个周期任务，比如每天03:00:00点删除sort set中前一天3点前的数据（保证set不无序增长、留近一天内活跃用户）。
取时，拿到当前时间戳（int 10位），再减1天就可按分数范围取过去24h活跃用户。



提供一种简单实现缓存失效的思路: LRU(最近少用的淘汰)
即redis的缓存每命中一次,就给命中的缓存增加一定ttl(过期时间)(根据具体情况来设定, 比如10分钟).
一段时间后, 热数据的ttl都会较大, 不会自动失效, 而冷数据基本上过了设定的ttl就马上失效了.