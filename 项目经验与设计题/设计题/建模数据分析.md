数据分析-创意产生-筛选人群-运营策略，活动-活动分析（效果如何）-效果评估

如何进行数据分析与诊断？确切的找出分析的数据的痛点所在？如果根据分析数据得出的结论，来提升运营的效果？

- 思路：
    - 1 确认问题：要从从分析的数据中得到哪些问题的答案
    - 2 数据准确性：分析的数据是否是准确的，有无冗余数据或者错误的数据
    - 3 多角度分析问题：
        - 天气：雨天，雪天，高温天气，
        - 节假日：国庆，双休日，新年烧香
        - 是否有补贴的因素
        - 竞品原因：T3，美团，曹操，首汽等等是否有更优的价格与更好的活动
        - 时间：是否上班或者节假日高峰期。
        - 地理位置：市中心商业区与郊区，普通区域
        - 用户结构与分层：学生，上班族，白领，打工族，  哪些更爱使用打车软件，使用怎么样的策略可以得到更好的收益。
        - 广告投放区域相关：有广告投放的区域 群众的认知度更高，使用我们的产品的人群更多？？
        
    
   - 方案：根据不同的查询条件，可以得出不同的数据统计。
        - 如：相同城市区域内，相同时间范围内：比较雨天与晴天对 数据指标（打车数量）的影响。
        - 定制用户画像（这里的用户需要有代表性：可以代表产品的主要受众和目标群体，进而分析用户行为，为用户提供和推荐具有针对性的运营手段）： 
        得知不同的人群在天气，时间，地理位置等各个条件下 的打车行为，最终可以定制推荐不同的运营策略给不同的种类用户。
        
        
- 技术相关实现：
    - 离线数据：T+1，T+2。。。 使用crontab定时任务，将mysql产生的数据放入hive临时表中，通过多hive临时表的聚合工作，在回写到具体的mysql业务表
    - 实时数据：canal+flinksql+kafka
        - 通过canal监听mysql bin log的变化，然后通过flink sql 将保存在kafka中的客户，风控，订单数据 事实表数据与
        销售店铺，车型车系维表进行join，然后产出的数据放入到我们的Mysql业务表中
    https://blog.csdn.net/hello_java_lcl/article/details/107025192
        - canal：将自己伪装成一个Mysql Slave，不断的向Master发送dump请求，mysql Master收到dump请求之后
          就会向canal推送bin log。canal解析出对应的binlog之后就可以进行二次消费了。
        - kafka：kafka是构建实时数仓常用的数据存储设备，使用Flink SQL创建kafka数据源表（也就是事实表）
            - 客户
            - 订单
            - 风控
            - 跟进
        - 维表创建：维表可能是会不断变化的，在维表JOIN时，需指明这条记录关联维表快照的时刻。
            - roc_order_detail：全款订单详情表
            - order_sku_json：订单明细表
            
        - flink SQL：将维表与事实表进行关联构建星型模型。  